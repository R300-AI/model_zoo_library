{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-qK-yGaK1aiC"
   },
   "source": [
    "# Export Classification Models via Torchvision\n",
    "\n",
    "> This script needs to be run on **Google Colab** or a **Custom Server**. If you are using a custom server, we also recommend that you set up a virtual environment via python-venv or conda before running this script, as it requires the specified version of the framework to run properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XIoRsalPGjyg",
    "outputId": "471c6708-3ea5-486f-e823-88c2d751d297",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==2.4.0\n",
      "  Downloading torch-2.4.0-cp38-cp38-manylinux1_x86_64.whl (797.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 797.2 MB 29 kB/s  eta 0:00:011   |██▏                             | 54.7 MB 3.4 MB/s eta 0:03:37     |█████▍                          | 134.4 MB 8.0 MB/s eta 0:01:23     |███████▋                        | 189.3 MB 5.7 MB/s eta 0:01:48     |███████████████▋                | 388.1 MB 10.1 MB/s eta 0:00:41     |█████████████████▏              | 427.6 MB 4.0 MB/s eta 0:01:33     |████████████████████▎           | 503.9 MB 524 kB/s eta 0:09:20MB 4.0 MB/s eta 0:00:571 MB 5.4 MB/s eta 0:00:08\n",
      "\u001b[?25hCollecting torchvision==0.19.0\n",
      "  Downloading torchvision-0.19.0-cp38-cp38-manylinux1_x86_64.whl (7.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.0 MB 1.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torchaudio==2.4.0\n",
      "  Downloading torchaudio-2.4.0-cp38-cp38-manylinux1_x86_64.whl (3.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.4 MB 460 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 410.6 MB 11 kB/s  eta 0:00:012   |███████████████▋                | 201.0 MB 510 kB/s eta 0:06:51     |████████████████                | 205.2 MB 1.9 MB/s eta 0:01:48��████████████████▊       | 317.8 MB 5.2 MB/s eta 0:00:18    |█████████████████████████████▍  | 376.6 MB 2.8 MB/s eta 0:00:12\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 121.6 MB 2.7 MB/s eta 0:00:01    |█████████████████▋              | 66.9 MB 4.6 MB/s eta 0:00:12��██              | 68.2 MB 4.6 MB/s eta 0:00:12     |██████████████████▍             | 70.0 MB 4.6 MB/s eta 0:00:12 MB 94 kB/s eta 0:05:41��████████▎    | 103.8 MB 1.2 MB/s eta 0:00:15\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 23.7 MB 2.1 MB/s eta 0:00:01��█████████████████▊      | 19.0 MB 74 kB/s eta 0:01:03     |██████████████████████████████  | 22.3 MB 2.1 MB/s eta 0:00:01ta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[K     |████████████████████████████████| 99 kB 2.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting triton==3.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version < \"3.13\"\n",
      "  Downloading triton-3.0.0-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 209.4 MB 749 kB/s eta 0:00:01     |████████████████████            | 131.3 MB 1.5 MB/s eta 0:00:52��███▉    | 182.2 MB 60 kB/s eta 0:07:32\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 124.2 MB 3.1 MB/s eta 0:00:01     |████████████████████████        | 93.5 MB 3.4 MB/s eta 0:00:10�███████▍    | 106.5 MB 731 kB/s eta 0:00:25\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 196.0 MB 334 kB/s eta 0:00:01    |███████████████                 | 91.2 MB 1.1 MB/s eta 0:01:39��        | 147.2 MB 63 kB/s eta 0:12:52��███▊    | 169.9 MB 52 kB/s eta 0:08:18███████▏| 190.9 MB 207 kB/s eta 0:00:25\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[K     |████████████████████████████████| 823 kB 852 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /home/r300/.local/lib/python3.8/site-packages (from torch==2.4.0) (3.1.4)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[K     |██████████████████████▌         | 9.9 MB 642 kB/s eta 0:00:07^C\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aCr6VZEN4izS"
   },
   "source": [
    "* Config the `model_name` and `torchvision.models.<backbone>` you want.\n",
    "\n",
    "> **Note**: You can find all the available model options in the official  [Torchvision](https://pytorch.org/vision/stable/models.html) documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iHxHeEgk8aHi",
    "outputId": "cd272525-012d-4e6f-8755-5e5e0a81fa0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/r300/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_11492/3926246098.py\", line 1, in <module>\n",
      "    import torch, torchvision\n",
      "ModuleNotFoundError: No module named 'torch'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/r300/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2105, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/home/r300/.local/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1396, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/r300/.local/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1287, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/r300/.local/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1140, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/r300/.local/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1030, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "  File \"/home/r300/.local/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1082, in get_records\n",
      "    style = stack_data.style_with_executing_node(style, self._tb_highlight)\n",
      "  File \"/home/r300/.local/lib/python3.8/site-packages/stack_data/core.py\", line 455, in style_with_executing_node\n",
      "    class NewStyle(style):\n",
      "  File \"/usr/lib/python3/dist-packages/pygments/style.py\", line 91, in __new__\n",
      "    ndef[4] = colorformat(styledef[3:])\n",
      "  File \"/usr/lib/python3/dist-packages/pygments/style.py\", line 58, in colorformat\n",
      "    assert False, \"wrong color format %r\" % text\n",
      "AssertionError: wrong color format 'ansiyellow'\n"
     ]
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "\n",
    "model_name = 'resnet18'\n",
    "model = torchvision.models.resnet18(True).cpu()\n",
    "model.eval()\n",
    "\n",
    "# You can also use the PyTorch API here to train the model and then convert it to runtime format, but remember to switch to eval() mode before doing so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MiRNB9PJ7ScZ"
   },
   "source": [
    "### Convert the Torch model into ONNX format\n",
    "\n",
    "Before converting to TFLite, be sure to check which OPS version of ONNX is supported by the accelerator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3QGJ-OsQ72Y7",
    "outputId": "be51bfa0-a0f7-4f98-878c-18366d3b565a"
   },
   "outputs": [],
   "source": [
    "!pip install onnxruntime\n",
    "!pip install onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5zyoaHnu51vA",
    "outputId": "7eb2067b-0941-46c7-b39a-87ebc2cd0c64"
   },
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "\n",
    "# Please set the input dimensions of the model and turn off the gradient mode to adjust it to run mode.\n",
    "inputs = torch.randn(1, 3, 320, 224, requires_grad=False).cpu()\n",
    "\n",
    "torch.onnx.export(model, inputs, f\"{model_name}.onnx\", verbose=False, opset_version=16, do_constant_folding=False, dynamic_axes=None)\n",
    "print(f\"Input shape: {onnxruntime.InferenceSession(f'{model_name}.onnx').get_inputs()[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ZPiLlNZ5ay9",
    "outputId": "0ebc93aa-70fd-4084-ffd7-d8b0163cd284"
   },
   "outputs": [],
   "source": [
    "# Verify the accuracy of the model output\n",
    "import numpy as np\n",
    "ort_session = onnxruntime.InferenceSession(f'{model_name}.onnx')\n",
    "np.unique(model(inputs).detach().numpy().astype(np.float16)==ort_session.run(None, {ort_session.get_inputs()[0].name: inputs.numpy()})[0].astype(np.float16), return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "peXaN1uV3UM8"
   },
   "source": [
    "### Convert the ONNX model into TFLite format\n",
    "\n",
    "Before converting to TFLite, check which OPS version of TFLite is supported by the accelerator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yLQyNyrFwdDE",
    "outputId": "77c32449-7004-487b-b5bc-fd5e08a30238"
   },
   "outputs": [],
   "source": [
    "!pip install keras\n",
    "!pip install tf_keras\n",
    "!pip install \"sng4onnx>=1.0.1\n",
    "!pip install \"onnx_graphsurgeon>=0.3.26\"\n",
    "!pip install \"onnx2tf>1.17.5,<=1.22.3\",\n",
    "!pip install \"onnxslim>=0.1.31\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U1ZF_I0xtbfa",
    "outputId": "6a881567-905d-4b4d-9a96-4120eebdef13"
   },
   "outputs": [],
   "source": [
    "import os, onnx2tf\n",
    "import tensorflow as tf\n",
    "\n",
    "!rm -rf {model_name}\n",
    "os.mkdir(model_name)\n",
    "\n",
    "onnx2tf.convert(\n",
    "    input_onnx_file_path=f\"{model_name}.onnx\",\n",
    "    output_folder_path=model_name,\n",
    "    not_use_onnxsim=True, non_verbose=False, verbosity=1,\n",
    "    copy_onnx_input_output_names_to_tflite=True,\n",
    "    output_integer_quantized_tflite=False,\n",
    "    quant_type=\"per-tensor\",  # \"per-tensor\" (faster) or \"per-channel\" (slower but more accurate)\n",
    ")\n",
    "\n",
    "print(f\"Input shape: {tf.lite.Interpreter(model_path=f'{model_name}/{model_name}_float32.tflite').get_input_details()[0]['shape']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S2DQShfi_B5l",
    "outputId": "b06df68b-ece3-4183-a07b-515ae778c417"
   },
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=f'{model_name}/{model_name}_float32.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "interpreter.set_tensor(interpreter.get_input_details()[0]['index'], inputs.permute(0, 2, 3, 1).numpy())\n",
    "interpreter.invoke()\n",
    "\n",
    "np.unique(model(inputs).detach().numpy()[0].astype(np.float16)==interpreter.get_tensor(interpreter.get_output_details()[0]['index'])[0].astype(np.float16), return_counts=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
