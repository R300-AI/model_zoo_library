{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Export Classification Models via Torchvision\n",
        "\n",
        "This script needs to be run on Google Colab or a custom server. If you are using a custom server, we also recommend that you set up a virtual environment via conda before running this script, as it requires the specified version of the framework to run properly.\n"
      ],
      "metadata": {
        "id": "-qK-yGaK1aiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0"
      ],
      "metadata": {
        "id": "XIoRsalPGjyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Config the `model_name` and `torchvision.models.<backbone>` you want.\n",
        "\n",
        "> **Note**: You can find all the available model options in the official  [Torchvision](https://pytorch.org/vision/stable/models.html) documentation."
      ],
      "metadata": {
        "id": "aCr6VZEN4izS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHxHeEgk8aHi"
      },
      "outputs": [],
      "source": [
        "#import torch, torchvision\n",
        "\n",
        "#model_name = 'resnet18'\n",
        "#model = torchvision.models.resnet18(True)\n",
        "\n",
        "# you can also training the model here using PyTorch APIs before convert to runtime format."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert the Torch model into ONNX format\n",
        "\n",
        "Before converting to TFLite, be sure to check which OPS version of ONNX is supported by the accelerator."
      ],
      "metadata": {
        "id": "MiRNB9PJ7ScZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install onnxruntime\n",
        "#!pip install onnx"
      ],
      "metadata": {
        "id": "3QGJ-OsQ72Y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import onnxruntime\n",
        "\n",
        "# Please set the input dimensions of the model and turn off the gradient mode to adjust it to run mode.\n",
        "#torch.onnx.export(model, torch.randn(1, 3, 224, 224, requires_grad=False), f\"{model_name}.onnx\", opset_version=16)\n",
        "#print(f\"Input shape: {onnxruntime.InferenceSession(f'{model_name}.onnx').get_inputs()[0].shape}\")"
      ],
      "metadata": {
        "id": "5zyoaHnu51vA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert the ONNX model into TFLite format\n",
        "\n",
        "Before converting to TFLite, check which OPS version of TFLite is supported by the accelerator.\n"
      ],
      "metadata": {
        "id": "peXaN1uV3UM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# onnx-tf was designed for TensorFlow 1.X, so force this version.\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "!pip install onnx-tf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "bQs0eVgKKpaY",
        "outputId": "c66dd7cf-6673-4e33-93da-5eb2674fc73f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Tensorflow 1 is unsupported in Colab.\n\nYour notebook should be updated to use Tensorflow 2.\nSee the guide at https://www.tensorflow.org/guide/migrate#migrate-from-tensorflow-1x-to-tensorflow-2.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-a7c93d33a152>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# onnx-tf was designed for TensorFlow 1.X, so force this version.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tensorflow_version'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'1.x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install onnx-tf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2416\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_local_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2417\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2418\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2419\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_tensorflow_magics.py\u001b[0m in \u001b[0;36m_tensorflow_version\u001b[0;34m(line)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;31m# pylint: disable=line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         textwrap.dedent(\n",
            "\u001b[0;31mValueError\u001b[0m: Tensorflow 1 is unsupported in Colab.\n\nYour notebook should be updated to use Tensorflow 2.\nSee the guide at https://www.tensorflow.org/guide/migrate#migrate-from-tensorflow-1x-to-tensorflow-2."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from onnx_tf.backend import prepare\n",
        "\n",
        "tf_rep = prepare(onnx.load(f'{model_name}.onnx'))\n",
        "tf_rep.export_graph('./onnx2tf')\n",
        "tf_model = tf.saved_model.load('./onnx2tf')\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model('./onnx2tf')\n",
        "\n",
        "# converter.allow_custom_ops = True\n",
        "# converter.experimental_new_converter = True\n",
        "# converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open(f'{model_name}.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)"
      ],
      "metadata": {
        "id": "rEWe6pM50BIJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}